#!/usr/bin/env python# -*- coding: utf-8 -*-# Created by spider3 on 2018/3/12# Copyright (c) 2018 spider3. All rights reserved.import jsonimport requestsfrom lxml import etreedef get_addr_id():    """    获取地址ID并返回    :return:    """    url = "http://www.monalisa.com.cn/store.html"    response = requests.get(url)    html = etree.HTML(response.text)    nodes = html.xpath('//select[@id="province"]/option/@value')    print(nodes[1:])    return nodes[1:]def get_info(str, page):    url = "http://www.monalisa.com.cn/Ajaxget.aspx"    data = {"act": "getinfo",            "str": str,            "page": page}    response = requests.get(url, data)    print("正在解析", str, "第", page, "页")    if "很抱歉，未找到专卖店" in response.text:        print("找不到：", str, "第", page, "页")        return None    html = etree.HTML(response.text)    nodes = html.xpath("//li")    data = []    for node in nodes:        tmp = {}        name = node.xpath("./div/a/text()")        phone_number = node.xpath("./div/em/text()")        addr = node.xpath("./div/p/text()")        tmp["name"] = name[0].strip()        tmp["phone_number"] = phone_number[0].strip() if phone_number else None        tmp["address"] = addr[0].strip()        data.append(tmp)    return datadef main():    addr_ids = get_addr_id()    all_data = []    # addr_ids = [32]    for addr_id in addr_ids:        for page in range(1, 4):            datas = get_info(str(addr_id), page)            if datas:                for i in datas:                    all_data.append(i)    str_data = json.dumps(all_data, ensure_ascii=False)    with open("../data/mona.json", "w") as f:        f.write(str_data)if __name__ == '__main__':    main()