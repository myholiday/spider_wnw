#!/usr/bin/env python# -*- coding: utf-8 -*-# Created by spider3 on 2018/3/26# Copyright (c) 2018 spider3. All rights reserved."""马可波罗瓷砖""""""http://www.marcopolo.com.cn/stores/"""import requestsimport jsonfrom lxml import etreefrom utils.save_pic import save_pic# 获取省urldef get_region_url():    url = 'http://www.marcopolo.com.cn/stores/'    response = requests.get(url)    html = etree.HTML(response.text)    region_urls = html.xpath('//div[@id="stores-filter"]/div[1]/a/@href')    region_urls = ["http://www.marcopolo.com.cn"+region_url for region_url in region_urls]    print(region_urls)    return region_urls# 获取详细urldef get_detail_url(region_url):    response = requests.get(region_url)    html = etree.HTML(response.text)    detail_urls = html.xpath('//ul[@class="row shadow-grid full-width m-v-l"]/li/a/@href')    detail_urls = ["http://www.marcopolo.com.cn" + detail_url for detail_url in detail_urls]    return detail_urls# 获取详细内容def get_detail(detail_url):    response = requests.get(detail_url)    url_id = detail_url.split('/')[-2]    if response.status_code == 404:        print("没有")        return None    html = etree.HTML(response.text)    node = html.xpath('//div[@class="col-sm-6 col-xs-12 p-h-m"]')[0]    tmp = {}    tmp['name'] = node.xpath('./h3/text()')[0]    tmp['address'] = node.xpath('./dl[1]/dd/text()')[0]    tmp['img_url'] = 'http://www.marcopolo.com.cn' + html.xpath('//div[@class="col-sm-6 col-xs-12 p-h-m m-b-m"]/img/@src')[0]    tmp['preview_image'] = 'shop-images/1368/{}.jpg'.format(url_id)    try:        tmp['phone_number'] = node.xpath('./dl[2]/dd/text()')[0]    except:        tmp['phone_number'] = 0    print(tmp)    return tmpdef spider():    li = []    detail_urls = []  # 记录详细页地址    region_urls = get_region_url()    for region_url in region_urls:        detail_urls += get_detail_url(region_url)    for detail_url in detail_urls:        one_data = get_detail(detail_url)        if one_data:            li.append(one_data)    try:        with open('../data/marcopolo.json','w') as f:            f.write(json.dumps(li,ensure_ascii=False))    except Exception as e:        print(e)        with open('../data/marcopolo.json','w') as f:            f.write(json.dumps(li))def download_pic():    with open('../data/marcopolo.json', 'r') as f:        data = json.loads(f.read())        for one_data in data:            save_pic(one_data['img_url'], "F:\\" ,one_data['preview_image'])            print('下载成功{}'.format(one_data['preview_image']))def main():    # spider()    download_pic()    # get_detail('http://www.marcopolo.com.cn/stores/store/7000/')if __name__ == '__main__':    main()